{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13336886,"sourceType":"datasetVersion","datasetId":8456676},{"sourceId":13338162,"sourceType":"datasetVersion","datasetId":8457685}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-11T16:34:46.380246Z","iopub.execute_input":"2025-10-11T16:34:46.380919Z","iopub.status.idle":"2025-10-11T16:34:46.653499Z","shell.execute_reply.started":"2025-10-11T16:34:46.380892Z","shell.execute_reply":"2025-10-11T16:34:46.652697Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/training/train.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install -q transformers accelerate bitsandbytes torch\n\nimport torch\nimport pandas as pd\nimport numpy as np\nimport re\nimport json\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nfrom tqdm.auto import tqdm\nfrom functools import lru_cache","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T16:34:47.026443Z","iopub.execute_input":"2025-10-11T16:34:47.026826Z","iopub.status.idle":"2025-10-11T16:36:17.272943Z","shell.execute_reply.started":"2025-10-11T16:34:47.026803Z","shell.execute_reply":"2025-10-11T16:36:17.272236Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"tqdm.pandas()\n\ndef initialize_model():\n    \"\"\"\n    Initializes and returns the LLM and tokenizer with 4-bit quantization.\n    This function sets up the model to run efficiently on a Colab T4 GPU.\n    \"\"\"\n    model_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n\n    quantization_config = BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_quant_type=\"nf4\",\n        bnb_4bit_compute_dtype=torch.bfloat16\n    )\n\n    tokenizer = AutoTokenizer.from_pretrained(model_id)\n    if tokenizer.pad_token is None:\n        tokenizer.pad_token = tokenizer.eos_token\n\n    model = AutoModelForCausalLM.from_pretrained(\n        model_id,\n        quantization_config=quantization_config,\n        device_map=\"auto\",\n    )\n    return model, tokenizer\n\n\ndef build_llm_prompt(description: str, tokenizer) -> str:\n    \"\"\"\n    Constructs the full few-shot prompt for the LLM.\n\n    Args:\n        description (str): The product description text.\n        tokenizer: The loaded Hugging Face tokenizer.\n\n    Returns:\n        str: The complete, formatted prompt ready for the LLM.\n    \"\"\"\n    system_prompt = f\"\"\"You are an expert e-commerce data analyst. Your task is to analyze a product description and extract structured information. You must return your response ONLY as a single, valid JSON object and nothing else.\n\n                    Extraction Rules:\n                    1.  product_category: Classify the product into a \"Primary-Secondary\" format (e.g., \"Food-Snacks\", \"Electronics-Headphones\").\n                    2.  concise_summary: Provide a brief summary including brand, product type, and key features. If no brand is mentioned, omit it. Key features must be the characteristics of what distinguishes or makes the product unique.\n                    3.  premium_rating: Assign a premium score from 1 (basic/generic) to 5 (luxury/high-end) based on the description.\n                    4.  quantity: Extract the numerical value. If it's not present or clear, return null. Do not convert the value (e.g., if it's 5000 milligrams, keep the quantity as 5000).\n                    5.  categorized_unit: Analyze the unit and return it in a \"category:standardized_unit\" string format. Decide the category based on the product and unit.\n                        * Categories must be one of: solid, fluid_volume, count, area, length, unknown.Some examples are mentioned\n                        STANDARDIZED_UNITS_LIST = [\n                        # Solid Weight:\"gram\", \"kilogram\", \"ounce\", \"pound\",\n                        # Fluid Volume :\"milliliter\", \"liter\", \"fluid_ounce\",\n                        # Count / Piece : \"piece\", \"pack\", \"bottle\", \"can\", \"bag\", \"box\", \"jar\", \"k-cup\", \"capsule\",\n                        # Area & Length : \"sq_ft\", \"foot\",\n                        # Undetermined\"undetermined\"]\n                        * Standardize the unit: Convert variations to a common form (e.g., If it is'milligram' or 'mg' becomes solid:milligram;'Fl.Oz.' becomes fluid_volume:fluid_ounce).\n                        * If a unit is a container or packaging type (e.g., 'Tea Bags', 'Carton'), use the count category and keep a clean unit name (e.g., count:tea_bag).\n                        * If the unit is not present or nonsensical (e.g., '-', 'NA'), use unknown:undetermined, unless the product type clearly implies a unit (e.g., headphones are count:piece).\"\"\"\n\n    few_shot_examples = \"\"\"\n    EXAMPLE 1\n    Description:\n    Indulge in the rich, creamy taste of Hershey's Milk Chocolate Bar. Made with farm-fresh milk, this classic American treat is perfect for s'mores or a simple snack. Each bar is crafted with care for a melt-in-your-mouth experience.\n    Value : 1.55\n    Unit : Oz\n    \n    JSON Output:\n    {\n      \"product_category\": \"Food-Chocolate\",\n      \"concise_summary\": \"Brand: Hershey's. Type: Milk Chocolate Bar. Features: Classic American treat, made with farm-fresh milk.\",\n      \"premium_rating\": 3,\n      \"quantity\": 1.55,\n      \"categorized_unit\": \"solid:ounce\"\n    }\n    ---\n    EXAMPLE 2\n    Description:\n    Experience true wireless freedom with the new AuraSound Pro 3 earbuds. Featuring advanced noise-cancellation technology, 24-hour battery life with the charging case, and crystal-clear audio. Bluetooth 5.3 provides a seamless connection.\n    Value : 1\n    Unit : NA\n    \n    JSON Output:\n    {\n      \"product_category\": \"Electronics-Earbuds\",\n      \"concise_summary\": \"Brand: AuraSound. Type:Wireless Earbuds. Features: Advanced noise-cancellation, 24-hour battery, Bluetooth 5.3.\",\n      \"premium_rating\": 4,\n      \"quantity\": 1,\n      \"categorized_unit\": \"count:piece\"\n    }\n    ---\n    EXAMPLE 3\n    Description:\n    Pure Creatine Monohydrate powder for muscle growth. Lab tested for purity and potency.\n    Value : 5000\n    Unit : milligram\n    \n    JSON Output:\n    {\n      \"product_category\": \"Health-Supplements\",\n      \"concise_summary\": \"Type: Creatine Monohydrate powder. Features: Lab tested for purity.\",\n      \"premium_rating\": 3,\n          \"quantity\": 5000,\n      \"categorized_unit\": \"solid:milligram\"\n    }\n    ---\n    EXAMPLE 4\n    Description:\n    High quality cleaning liquid. Works great on all surfaces. Get yours today!\n    Value : NA\n    Unit : NA\n    \n    JSON Output:\n    {\n      \"product_category\": \"Household-Cleaning\",\n      \"concise_summary\": \"Type: Cleaning liquid. Features: Works on all surfaces.\",\n      \"premium_rating\": 2,\n      \"quantity\": null,\n      \"categorized_unit\": \"unknown:undetermined\"\n    }\n    \"\"\"\n\n    user_prompt = f\"\"\"\n    *Description:*\n    {description}\n    \n    *JSON Output:*\n    \"\"\"\n\n    messages = [\n        {\"role\": \"user\", \"content\": system_prompt + few_shot_examples + user_prompt}\n    ]\n\n    final_prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    return final_prompt\n\n\ndef get_structured_data_from_llm(prompt: str, model, tokenizer) -> dict:\n    \"\"\"\n    Sends a prompt to the LLM and parses the JSON response.\n\n    Args:\n        prompt (str): The fully formatted prompt.\n        model: The loaded Hugging Face model.\n        tokenizer: The loaded Hugging Face tokenizer.\n\n    Returns:\n        dict: A dictionary containing the extracted features, or a default dict on failure.\n    \"\"\"\n    default_response = {\n        \"product_category\": None, \"concise_summary\": None, \"premium_rating\": None,\n        \"quantity\": None, \"unit\": None\n    }\n\n    try:\n        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=4096).to(\"cuda\")\n        input_token_length = inputs.input_ids.shape[1]\n\n        outputs = model.generate(\n            **inputs,\n            max_new_tokens=256,\n            temperature=0.1,\n            do_sample=True,\n            pad_token_id=tokenizer.eos_token_id\n        )\n\n        generated_token_ids = outputs[0, input_token_length:]\n        response_text = tokenizer.decode(generated_token_ids, skip_special_tokens=True)\n\n        json_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n\n        if json_match:\n            json_str = json_match.group(0)\n            if json_str.strip():\n                return json.loads(json_str)\n            else:\n                print(\"Warning: Empty JSON string found.\")\n                return default_response\n        else:\n            print(f\"Warning: No valid JSON object found in model response:\\n{response_text}\")\n            return default_response\n\n    except Exception as e:\n        print(f\"An error occurred during LLM inference or JSON parsing: {e}\")\n        return default_response\ndata = pd.read_csv('/kaggle/input/training/train.csv')\ndf = pd.DataFrame(data[10000:15000])\n\nmodel, tokenizer = initialize_model()\n\ndef augment_row(row):\n    description = row['catalog_content']\n    prompt = build_llm_prompt(description, tokenizer)\n    structured_data = get_structured_data_from_llm(prompt, model, tokenizer)\n\n    value_pattern = re.compile(r\"Value\\s*:\\s*(.*)\")\n    unit_pattern = re.compile(r\"Unit\\s*:\\s*(.*)\")\n\n    # --- Initialize variables ---\n    extracted_value = None\n    extracted_unit = None\n\n    # --- Process the last two lines ---\n    # Split the text into lines and get the last two non-empty lines\n    lines = [line for line in description.strip().split('\\n') if line.strip()][-2:]\n\n    for line in lines:\n        value_match = value_pattern.search(line)\n        unit_match = unit_pattern.search(line)\n        \n        # If the value pattern matches, extract and strip the result\n        if value_match:\n            # group(1) gets the content from the parentheses (.*)\n            extracted_value = value_match.group(1).strip()\n            \n        # If the unit pattern matches, extract and strip the result\n        if unit_match:\n            extracted_unit = unit_match.group(1).strip()\n    structured_data[\"regex_unit\"] = extracted_unit\n    structured_data[\"regex_value\"] = extracted_value\n\n    \n    return pd.Series(structured_data)\n\naugmented_data = df.progress_apply(augment_row, axis=1)\ndf_augmented = pd.concat([df, augmented_data], axis=1)\n\ndf_augmented['quantity'] = pd.to_numeric(df_augmented['quantity'], errors='coerce')\ndf_augmented['price_per_unit'] = df_augmented['price'] / df_augmented['quantity']\ndf_augmented['price_per_unit'].replace([np.inf, -np.inf], np.nan, inplace=True)\ndf_augmented.to_csv('augmented_data_3.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T16:36:17.274385Z","iopub.execute_input":"2025-10-11T16:36:17.275312Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef087ebc74494851b92a401aa9cdb179"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/587k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c352e8901e14caeaef6d232562d9043"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83d363f9673b4771811d4e7485ccc851"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92c786c046e44ec2aa112dc041dba7cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/601 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10fcd9187108469bacfb612bdc7ebaae"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n2025-10-11 16:36:29.386379: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1760200589.558326      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1760200589.609620      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0b77e1ef19e4481b43a6f4a8ae432dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0425cb2cf54a489aa27a95a5fbddccce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"568e3d06870e4eaa989a9bbf76dc705a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bcdca9db8bd4a7d920755fda0e102ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/4.55G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e5ab3c3207445789116e6c4fe813f91"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32eb91a8205c4f0db12c79eba20f3652"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3adcc0ddcdf4b99bdb444b7a149e9d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"907f16a3b77d462f8d043115edb2d931"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T15:38:57.538425Z","iopub.execute_input":"2025-10-11T15:38:57.53918Z","iopub.status.idle":"2025-10-11T15:38:57.548794Z","shell.execute_reply.started":"2025-10-11T15:38:57.539154Z","shell.execute_reply":"2025-10-11T15:38:57.548025Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_augmented","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-11T15:36:20.986594Z","iopub.execute_input":"2025-10-11T15:36:20.987248Z","iopub.status.idle":"2025-10-11T15:36:21.009291Z","shell.execute_reply.started":"2025-10-11T15:36:20.987229Z","shell.execute_reply":"2025-10-11T15:36:21.008669Z"}},"outputs":[],"execution_count":null}]}